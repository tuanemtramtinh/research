{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0d7824ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, TypedDict\n",
    "import spacy\n",
    "from textacy import extract, preprocessing\n",
    "from typing import Annotated\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from spacy.tokens import Doc\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "152f637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "#Danh sách từ không được tính là Actors\n",
    "INTERNAL_SYSTEM_KEYWORDS = {\"system\", \"software\", \"application\", \"app\", \"platform\"}\n",
    "\n",
    "model = init_chat_model(\n",
    "  \"gpt-5-mini\",\n",
    "  model_provider=\"openai\",\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59327fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationResult(BaseModel):\n",
    "  is_valid: bool = Field(description=\"True if the data is accurate, False if it is not valid\")\n",
    "  reason: str = Field(description=\"The reason why the data is not valid\")\n",
    "  \n",
    "class AliasItem(BaseModel):\n",
    "  alias: str = Field(description=\"Name of the alias\")\n",
    "  sentences: List[int] = Field(description=\"List of sentence indices where THIS specific alias appears (starting from 1)\")\n",
    "\n",
    "class ActorAlias(BaseModel):\n",
    "  actor: str = Field(description=\"The original actor's name\")\n",
    "  aliases: List[AliasItem] = Field(description=\"List of alternative names/references for this actor\")\n",
    "  \n",
    "  def __str__(self) -> str:\n",
    "    alias_str = \"\\n  \".join([f\"- {item.alias}: sentences {item.sentences}\" for item in self.aliases]) if self.aliases else \"None\"\n",
    "    \n",
    "    return (\n",
    "        f\"ACTOR: {self.actor}\\n\"\n",
    "        f\"  Aliases:\\n  {alias_str}\\n\"\n",
    "        f\"{'-'*50}\"\n",
    "    )\n",
    "\n",
    "class ActorList(BaseModel):\n",
    "  actors: List[str] = Field(description=\"A list of actors who perform actions in the requirement.\")\n",
    "  \n",
    "class ActorAliasMapping(BaseModel):\n",
    "  mappings: List[ActorAlias] = Field(description=\"List of actor-alias mappings\")\n",
    "\n",
    "class UseCase(BaseModel):\n",
    "  usecase: str = Field(description=\"The name of the use case (e.g., 'Place Order')\")\n",
    "  actor: str = Field(description=\"The actor who performs this use case\")\n",
    "  verb_phrase: str = Field(description=\"The extracted verb phrase\")\n",
    "  sentence: str = Field(description=\"The sentence where this use case was found\")\n",
    "  \n",
    "  def __str__(self) -> str:\n",
    "    return (\n",
    "        f\"USECASE: {self.usecase}\\n\"\n",
    "        f\"Actor: {self.actor}\\n\"\n",
    "        f\"Verb Phrase: {self.verb_phrase}\\n\"\n",
    "        f\"Sentence: {self.sentence}\\n\"\n",
    "        f\"{'-'*30}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f77358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo State cho Graph\n",
    "class GraphState(TypedDict):\n",
    "  input_text: str     #Yêu cầu đầu vào của người dùng\n",
    "  doc: Doc            #Doc sau khi gọi hàm nlp của SpaCy\n",
    "  actors: List[str]   #Danh sách actors cuối cùng\n",
    "  actor_aliases: List[ActorAlias] #Danh sách các alias của actor\n",
    "  usecases: List[UseCase] #Danh sách use cases\n",
    "  svo_elements: Annotated[List[Dict[str,str]], operator.add]\n",
    "  validation_actor_result: ValidationResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f180e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actors node\n",
    "def actors_node(state: GraphState):\n",
    "  structured_llm = model.with_structured_output(ActorList)\n",
    "  candidate_chunks = \", \".join(state[\"actors\"])\n",
    "  \n",
    "  system_prompt = (\n",
    "    \"You are a Senior Systems Analyst and Linguistic Expert. Your task is to perform \"\n",
    "    \"Entity Extraction specifically for 'Actors' in a system description or user story. \"\n",
    "    \"An 'Actor' is defined as a person, organization, or external system that \"\n",
    "    \"performs actions, initiates processes, or interacts with the system described.\"\n",
    ")\n",
    "\n",
    "  user_prompt = f\"\"\"\n",
    "  I will provide you with a raw text and a list of potential 'Noun Chunks' extracted by a parser.\n",
    "\n",
    "  ### RULES:\n",
    "  1. **Filtering**: From the 'Candidate Noun Chunks', select only those that function as an active agent (Actor) in the 'Raw Text'.\n",
    "  2. **Standardization**: Convert all extracted actors to their **singular form** (e.g., 'customers' -> 'customer').\n",
    "  3. **Cleaning**: Remove any unnecessary articles (a, an, the) and honorifics.\n",
    "  4. **Context Check**: Ensure the noun chunk is actually performing an action in the text, not just being mentioned as an object.\n",
    "  5. **Exclude Self-References**: Do NOT include 'the system', 'the software', or 'the application' as an Actor if it refers to the system being described. These are internal components, not external actors.\n",
    "  6. **External Systems**: Only include other specific systems if they are external entities that your system interacts with (e.g., 'Payment Gateway', 'External Database').\n",
    "  \n",
    "  ### INPUT DATA:\n",
    "  - Raw Text: {state['input_text']}\n",
    "  - Candidate Noun Chunks: {candidate_chunks}\n",
    "\n",
    "  ### OUTPUT INSTRUCTIONS:\n",
    "  Return only the final list of singularized actors.\n",
    "  \"\"\"\n",
    "    \n",
    "  response: ActorList = structured_llm.invoke([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", user_prompt)\n",
    "  ])\n",
    "  \n",
    "  # print(response)\n",
    "  \n",
    "  return {\n",
    "    \"actors\": response.actors\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8c659498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actors_alias_node\n",
    "\n",
    "def actors_alias_node(state: GraphState):\n",
    "  sentences = state.get(\"doc\").sents\n",
    "  \n",
    "  structured_llm = model.with_structured_output(ActorAliasMapping)\n",
    "  \n",
    "  # Đầu vào cho LLMs\n",
    "  input_sentences = [sentence.text.strip() for sentence in sentences]\n",
    "  input_sentences = \"\\n\".join([f\"{i + 1}. {s}\" for i, s in enumerate(input_sentences)])\n",
    "  \n",
    "  actors_list = \", \".join(state.get(\"actors\"))\n",
    "  \n",
    "  system_prompt = (\n",
    "    \"You are an expert in Natural Language Processing and Entity Resolution. \"\n",
    "    \"Your task is to identify all alternative references (aliases) to specific actors \"\n",
    "    \"in a given text and map EACH UNIQUE ALIAS to the specific sentences where it appears.\"\n",
    "  )\n",
    "  \n",
    "  user_prompt = f\"\"\"\n",
    "  Analyze the following pre-segmented numbered sentences and identify all references to the given actors.\n",
    "\n",
    "  ### ACTORS TO TRACK:\n",
    "  {actors_list}\n",
    "\n",
    "  ### PRE-SEGMENTED SENTENCES:\n",
    "  {input_sentences}\n",
    "\n",
    "  ### CRITICAL INSTRUCTIONS:\n",
    "  - **Each unique alias must be tracked separately** with its own sentence list\n",
    "  - Even slight variations count as different aliases (e.g., \"customer\" vs \"the customer\" are TWO separate aliases)\n",
    "  - DO NOT merge aliases together - keep them distinct\n",
    "  - Each alias should map ONLY to sentences where that EXACT form appears\n",
    "\n",
    "  ### TASK:\n",
    "  For each actor:\n",
    "  1. Identify ALL distinct ways it is referenced (exact name, pronouns, role titles, variations)\n",
    "  2. For EACH unique alias, list the sentence numbers where THAT SPECIFIC alias appears\n",
    "  3. Treat each variation as a separate alias entry\n",
    "\n",
    "  ### EXAMPLES:\n",
    "  If \"customer\" appears in sentences 1, 3 and \"the customer\" appears in sentences 2, 4:\n",
    "```\n",
    "  aliases: [\n",
    "    {{ alias: \"customer\", sentences: [1, 3] }},\n",
    "    {{ alias: \"the customer\", sentences: [2, 4] }}\n",
    "  ]\n",
    "```\n",
    "\n",
    "  If \"he\" appears in sentence 5 referring to customer:\n",
    "```\n",
    "  {{ alias: \"he\", sentences: [5] }}\n",
    "```\n",
    "\n",
    "  ### COREFERENCE RULES:\n",
    "  - Track pronoun chains: if \"he\" in sentence 5 refers to \"customer\" in sentence 1, add \"he\" as a separate alias for the customer actor\n",
    "  - Resolve possessive pronouns (his, her, their) to their antecedents\n",
    "  - Identify role-based references (the admin, admin, administrator - all separate aliases)\n",
    "  - Each demonstrative reference is a unique alias (this person, that user)\n",
    "\n",
    "  ### OUTPUT REQUIREMENTS:\n",
    "  - In the 'sentences' field, use ONLY the sentence number (integer starting from 1)\n",
    "  - Each alias must appear as a separate AliasItem\n",
    "  - Do NOT combine or merge similar aliases\n",
    "  \"\"\"\n",
    "  \n",
    "  response: ActorAliasMapping = structured_llm.invoke([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", user_prompt)\n",
    "  ])\n",
    "  \n",
    "  \n",
    "  # result = []\n",
    "  \n",
    "  # for item in response.mappings:\n",
    "  #   item.sentences = [sentence[0] for sentence in item.sentences]\n",
    "  #   print(item.sentences)\n",
    "  # print(result)\n",
    "  \n",
    "  return {\n",
    "    \"actor_aliases\": response.mappings\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "db79b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#revalidate actors list\n",
    "\n",
    "def actors_validate_node(state: GraphState):\n",
    "  \n",
    "  structured_llm = model.with_structured_output(ValidationResult)\n",
    "  \n",
    "  #input\n",
    "  \n",
    "  input_actors = state.get(\"actors\")\n",
    "  input_actors_alias = \"\\n\".join([str(alias) for alias in state.get(\"actor_aliases\")])\n",
    "  input_text = state.get(\"input_text\")\n",
    "  \n",
    "  system_prompt = \"\"\"You are a data validation expert specializing in entity recognition and alias validation.\n",
    "\n",
    "Your task is to validate actors (entities) and their aliases against the original raw input to ensure:\n",
    "1. All actors mentioned in the raw input are captured\n",
    "2. Aliases correctly refer to their corresponding actors\n",
    "3. Sentence indices are valid and correctly reference sentences in the raw input\n",
    "4. Aliases appear in the referenced sentences\n",
    "5. No duplicate or conflicting aliases across different actors\n",
    "6. Aliases are meaningful and contextually appropriate\n",
    "7. All actors have complete information (name, aliases, sentence indices)\n",
    "\n",
    "Note: Sentence indices start from 1 and reference the position of sentences in the raw input.\n",
    "\n",
    "Return a structured validation result with:\n",
    "- is_valid: boolean indicating if validation passed\n",
    "- errors: list of specific validation errors found (critical issues)\n",
    "- warnings: list of potential issues that don't fail validation\n",
    "- suggestions: list of recommended improvements\"\"\"\n",
    "  \n",
    "  human_prompt = f\"\"\"Please validate the following actors and their aliases against the original raw input:\n",
    "\n",
    "**Raw Input:**\n",
    "{input_text}\n",
    "\n",
    "**Actors List:**\n",
    "{input_actors}\n",
    "\n",
    "**Actor Aliases with Sentence Indices:**\n",
    "{input_actors_alias}\n",
    "\n",
    "Check for:\n",
    "1. All actors from raw input are included in the actors list\n",
    "2. Each actor has corresponding alias information\n",
    "3. Sentence indices are valid (within range of sentences in raw input, starting from 1)\n",
    "4. The actor or its aliases actually appear in the referenced sentences\n",
    "5. No alias conflicts (same alias for different actors)\n",
    "6. No duplicate aliases within the same actor\n",
    "7. Sentence indices are correct and reference the right sentences\n",
    "8. Format consistency across all ActorAlias entries\n",
    "9. Completeness: each actor has at least name and sentence indices\n",
    "10. No hallucinated actors or aliases not in raw input\n",
    "11. No invalid sentence indices (e.g., index 0, negative numbers, or exceeding total sentence count)\n",
    "\n",
    "Provide detailed validation results with specific examples of any issues found.\"\"\"\n",
    "  \n",
    "  response: ValidationResult = structured_llm.invoke([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", human_prompt)\n",
    "  ])\n",
    "  \n",
    "  print(response)\n",
    "  \n",
    "  return {\n",
    "    \"validation_actor_result\": response\n",
    "  }\n",
    "  \n",
    "def decide_after_actor_validation(state:GraphState):\n",
    "  validation_result = state.get(\"validation_actor_result\")\n",
    "  if validation_result and validation_result.is_valid:\n",
    "      return \"valid\"  # Tiếp tục flow bình thường\n",
    "  else:\n",
    "      return \"invalid\"  # Cần xử lý lại hoặc sửa lỗi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "55627be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define usecase node\n",
    "\n",
    "def define_usecase_node(state: GraphState):\n",
    "  \n",
    "  \n",
    "  \n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c784d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"actors_node\", actors_node)\n",
    "workflow.add_node(\"actors_alias_node\", actors_alias_node)\n",
    "# workflow.add_node(\"actors_validate_node\", actors_validate_node)\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"actors_node\")\n",
    "workflow.add_edge(\"actors_node\", \"actors_alias_node\")\n",
    "workflow.add_edge(\"actors_alias_node\", END)\n",
    "\n",
    "# workflow.add_edge(\"actors_alias_node\", \"actors_validate_node\")\n",
    "# workflow.add_conditional_edges(\n",
    "#   \"actors_validate_node\",\n",
    "#   decide_after_actor_validation,\n",
    "#   {\n",
    "#     \"valid\": END,\n",
    "#     \"invalid\": \"actors_node\"\n",
    "#   }\n",
    "# )\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82938c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ACTORS ===\n",
      "['librarian', 'student', 'automated kiosk', 'administrator']\n",
      "\n",
      "=== ACTOR ALIASES ===\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AliasItem' object has no attribute 'alias'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== ACTOR ALIASES ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result.get(\u001b[33m\"\u001b[39m\u001b[33mactor_aliases\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m   \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mActorAlias.__str__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m   alias_str = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mitem\u001b[49m\u001b[43m.\u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: sentences \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem.sentences\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aliases]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aliases \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     17\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mACTOR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.actor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Aliases:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/research/.venv/lib/python3.12/site-packages/pydantic/main.py:1026\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'AliasItem' object has no attribute 'alias'"
     ]
    }
   ],
   "source": [
    "with open(\"./input.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "  input = f.read()\n",
    "  \n",
    "input = preprocessing.normalize.whitespace(input)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(input)\n",
    "\n",
    "chunks = extract.noun_chunks(doc, min_freq=1)\n",
    "chunks = [chunk.text for chunk in chunks if chunk.root.pos_ != 'PRON' and chunk.root.lemma_.lower() not in INTERNAL_SYSTEM_KEYWORDS]\n",
    "\n",
    "#Trạng thái khởi tạo ban đầu cho process\n",
    "initial_state = {\n",
    "  \"input_text\": input,\n",
    "  \"doc\": doc,\n",
    "  \"actors\": chunks,\n",
    "  \"actor_aliases\": [],\n",
    "  \"usecases\": [],\n",
    "  \"svo_elements\": [],\n",
    "}\n",
    "\n",
    "result: GraphState = app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n=== ACTORS ===\")\n",
    "print(result.get(\"actors\"))\n",
    "print(\"\\n=== ACTOR ALIASES ===\")\n",
    "for item in result.get(\"actor_aliases\"):\n",
    "  print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
