{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0d7824ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, TypedDict\n",
    "import spacy\n",
    "from textacy import extract, preprocessing\n",
    "from typing import Annotated\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from spacy.tokens import Doc\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "#Danh sách từ không được tính là Actors\n",
    "INTERNAL_SYSTEM_KEYWORDS = {\"system\", \"software\", \"application\", \"app\", \"platform\"}\n",
    "\n",
    "model = init_chat_model(\n",
    "  \"gpt-5-mini\",\n",
    "  model_provider=\"openai\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0f77358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo State cho Graph\n",
    "class GraphState(TypedDict):\n",
    "  input_text: str     #Yêu cầu đầu vào của người dùng\n",
    "  doc: Doc            #Doc sau khi gọi hàm nlp của SpaCy\n",
    "  actors: List[str]   #Danh sách actors cuối cùng\n",
    "  svo_elements: Annotated[List[Dict[str,str]], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "14a36130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorList(BaseModel):\n",
    "  actors: List[str] = Field(description=\"Danh sách các tác nhân (Actors) thực hiện hành động trong văn bản\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f180e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actors node\n",
    "def actors_node(state: GraphState):\n",
    "  structured_llm = model.with_structured_output(ActorList)\n",
    "  candidate_chunks = \", \".join(state[\"actors\"])\n",
    "  \n",
    "  system_prompt = (\n",
    "    \"You are a Senior Systems Analyst and Linguistic Expert. Your task is to perform \"\n",
    "    \"Entity Extraction specifically for 'Actors' in a system description or user story. \"\n",
    "    \"An 'Actor' is defined as a person, organization, or external system that \"\n",
    "    \"performs actions, initiates processes, or interacts with the system described.\"\n",
    ")\n",
    "\n",
    "  user_prompt = f\"\"\"\n",
    "  I will provide you with a raw text and a list of potential 'Noun Chunks' extracted by a parser.\n",
    "\n",
    "  ### RULES:\n",
    "  1. **Filtering**: From the 'Candidate Noun Chunks', select only those that function as an active agent (Actor) in the 'Raw Text'.\n",
    "  2. **Standardization**: Convert all extracted actors to their **singular form** (e.g., 'customers' -> 'customer').\n",
    "  3. **Cleaning**: Remove any unnecessary articles (a, an, the) and honorifics.\n",
    "  4. **Context Check**: Ensure the noun chunk is actually performing an action in the text, not just being mentioned as an object.\n",
    "  5. **Exclude Self-References**: Do NOT include 'the system', 'the software', or 'the application' as an Actor if it refers to the system being described. These are internal components, not external actors.\n",
    "  6. **External Systems**: Only include other specific systems if they are external entities that your system interacts with (e.g., 'Payment Gateway', 'External Database').\n",
    "  \n",
    "  ### INPUT DATA:\n",
    "  - Raw Text: {state['input_text']}\n",
    "  - Candidate Noun Chunks: {state['actors']}\n",
    "\n",
    "  ### OUTPUT INSTRUCTIONS:\n",
    "  Return only the final list of singularized actors.\n",
    "  \"\"\"\n",
    "    \n",
    "  response = structured_llm.invoke([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", user_prompt)\n",
    "  ])\n",
    "  \n",
    "  # print(response)\n",
    "  \n",
    "  return {\n",
    "    \"actors\": response.actors\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7c784d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"actors_node\", actors_node)\n",
    "\n",
    "workflow.add_edge(START, \"actors_node\")\n",
    "workflow.add_edge(\"actors_node\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "82938c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['librarian', 'student', 'automated kiosk', 'administrator']\n"
     ]
    }
   ],
   "source": [
    "with open(\"./input.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "  input = f.read()\n",
    "  \n",
    "input = preprocessing.normalize.whitespace(input)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(input)\n",
    "\n",
    "chunks = extract.noun_chunks(doc, min_freq=1)\n",
    "chunks = [chunk.text for chunk in chunks if chunk.root.pos_ != 'PRON' and chunk.root.lemma_.lower() not in INTERNAL_SYSTEM_KEYWORDS]\n",
    "\n",
    "initial_state = {\n",
    "  \"input_text\": input,\n",
    "  \"doc\": doc,\n",
    "  \"actors\": chunks,\n",
    "  \"svo_elements\": []\n",
    "}\n",
    "\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "print(result.get(\"actors\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
